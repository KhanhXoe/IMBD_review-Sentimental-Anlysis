{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857340fe",
   "metadata": {},
   "source": [
    "# EDA corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0083ab4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T03:47:19.901347Z",
     "iopub.status.busy": "2025-08-31T03:47:19.900640Z",
     "iopub.status.idle": "2025-08-31T03:47:19.904579Z",
     "shell.execute_reply": "2025-08-31T03:47:19.903956Z",
     "shell.execute_reply.started": "2025-08-31T03:47:19.901321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883221e",
   "metadata": {},
   "source": [
    "## Cumulating the dataset from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa882635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T03:47:21.173678Z",
     "iopub.status.busy": "2025-08-31T03:47:21.173191Z",
     "iopub.status.idle": "2025-08-31T03:48:27.597172Z",
     "shell.execute_reply": "2025-08-31T03:48:27.596547Z",
     "shell.execute_reply.started": "2025-08-31T03:47:21.173655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:09<00:00, 1270.55it/s]\n",
      "100%|██████████| 12500/12500 [00:56<00:00, 221.03it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_file_path = r'/kaggle/input/aclimdb/aclImdb/train/pos'\n",
    "neg_file_path = r'/kaggle/input/aclimdb/aclImdb/train/neg'\n",
    "\n",
    "def get_data(pos_folder_path, neg_folder_path):\n",
    "    pos_context = []\n",
    "    neg_context = []\n",
    "\n",
    "    for filename in tqdm(os.listdir(pos_folder_path)):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(pos_folder_path, filename)\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                pos_context.append(content)\n",
    "\n",
    "    for filename in tqdm(os.listdir(neg_folder_path)):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(neg_folder_path, filename)\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                neg_context.append(content)\n",
    "    \n",
    "    pos_label = [0]*len(pos_context)\n",
    "    neg_label = [1]*len(neg_context)\n",
    "    text = pos_context+neg_context\n",
    "    label = pos_label+neg_label\n",
    "    \n",
    "    data = pd.DataFrame({'Context':text, 'Label':label})\n",
    "\n",
    "    return data\n",
    "\n",
    "frame = get_data(pos_file_path, neg_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98f7ded7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T03:49:47.171830Z",
     "iopub.status.busy": "2025-08-31T03:49:47.171102Z",
     "iopub.status.idle": "2025-08-31T03:49:47.179894Z",
     "shell.execute_reply": "2025-08-31T03:49:47.179120Z",
     "shell.execute_reply.started": "2025-08-31T03:49:47.171803Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was one of those wonderful rare moments i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you seen The Graduate? It was hailed as t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't watch a lot of TV, except for The Offi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kubrick again puts on display his stunning abi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First of all, I liked very much the central id...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>The first hour of the movie was boring as hell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>A fun concept, but poorly executed. Except for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I honestly don't understand how tripe like thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>This remake of the 1962 orginal film'o the boo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>La Sanguisuga Conduce la Danza, or The Bloodsu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Context  Label\n",
       "0      This was one of those wonderful rare moments i...      0\n",
       "1      Have you seen The Graduate? It was hailed as t...      0\n",
       "2      I don't watch a lot of TV, except for The Offi...      0\n",
       "3      Kubrick again puts on display his stunning abi...      0\n",
       "4      First of all, I liked very much the central id...      0\n",
       "...                                                  ...    ...\n",
       "24995  The first hour of the movie was boring as hell...      1\n",
       "24996  A fun concept, but poorly executed. Except for...      1\n",
       "24997  I honestly don't understand how tripe like thi...      1\n",
       "24998  This remake of the 1962 orginal film'o the boo...      1\n",
       "24999  La Sanguisuga Conduce la Danza, or The Bloodsu...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff36eeb",
   "metadata": {},
   "source": [
    "## Removing unnecessary parttern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7581d332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T03:52:48.959273Z",
     "iopub.status.busy": "2025-08-31T03:52:48.958578Z",
     "iopub.status.idle": "2025-08-31T03:52:50.764712Z",
     "shell.execute_reply": "2025-08-31T03:52:50.764165Z",
     "shell.execute_reply.started": "2025-08-31T03:52:48.959252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "frame['CleanedContext'] = frame['Context'].apply(lambda x: x.replace('<br />', ' '))\n",
    "frame['CleanedContext'] = frame['CleanedContext'].replace(r'\\s+', ' ', regex=True)\n",
    "frame['CleanedContext'] = frame['CleanedContext'].apply(lambda x: x.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b9c5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T03:52:51.508747Z",
     "iopub.status.busy": "2025-08-31T03:52:51.508056Z",
     "iopub.status.idle": "2025-08-31T03:52:51.512937Z",
     "shell.execute_reply": "2025-08-31T03:52:51.512325Z",
     "shell.execute_reply.started": "2025-08-31T03:52:51.508697Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Does any one know what the 2 sports cars were? I think Robert Stack's might have been a Masseratti.Rock Hudson's character told his father he was taking a job in Iraq ,isn't that timely? I have had Dorthy Malone in my spank bank most of my life ,maybe this was the film that impressed me.Loren Bacall sure did have some chops in this film and probably out-acted Malone but Malones's part made a more sensational impact so she got the Oscar for best supporting role.Was Loren's part considered a leading role?Old man Hadley character was was probably a pretty common picture of tycoons of his era in that he was a regular guy who made it big in an emerging industry but in building a whole town he had forgotten his children to have his wife bring them up.In time,being widowed he realized that they were all he really had and they were spoiled rotten,looking for attention,so rather than try to relate to his children he blew his head off.An ancient morality tale.But seriously,what were those sports cars?\n",
      "\n",
      "\n",
      "After cleaning:\n",
      "Does any one know what the 2 sports cars were? I think Robert Stack's might have been a Masseratti.Rock Hudson's character told his father he was taking a job in Iraq ,isn't that timely? I have had Dorthy Malone in my spank bank most of my life ,maybe this was the film that impressed me.Loren Bacall sure did have some chops in this film and probably out-acted Malone but Malones's part made a more sensational impact so she got the Oscar for best supporting role.Was Loren's part considered a leading role?Old man Hadley character was was probably a pretty common picture of tycoons of his era in that he was a regular guy who made it big in an emerging industry but in building a whole town he had forgotten his children to have his wife bring them up.In time,being widowed he realized that they were all he really had and they were spoiled rotten,looking for attention,so rather than try to relate to his children he blew his head off.An ancient morality tale.But seriously,what were those sports cars?\n"
     ]
    }
   ],
   "source": [
    "i = 1000\n",
    "print('Before cleaning:')\n",
    "print(frame['Context'][i])\n",
    "print(\"\\n\")\n",
    "print('After cleaning:')\n",
    "print(frame['Context'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a254582a",
   "metadata": {},
   "source": [
    "## Tokenizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32877899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T03:53:38.560111Z",
     "iopub.status.busy": "2025-08-31T03:53:38.559833Z",
     "iopub.status.idle": "2025-08-31T03:53:47.462899Z",
     "shell.execute_reply": "2025-08-31T03:53:47.461997Z",
     "shell.execute_reply.started": "2025-08-31T03:53:38.560085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b15ebe84a17408c979be2148cb94432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b40adbc1f0418fb6f90a13830f00d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab57d51750747b88d773bb442962e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c877852448643c9bc174b139fcd10a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc4f02",
   "metadata": {},
   "source": [
    "## Batch-tokenizing and Padding phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c09d1fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:35:16.575887Z",
     "iopub.status.busy": "2025-08-31T04:35:16.575560Z",
     "iopub.status.idle": "2025-08-31T04:36:48.150786Z",
     "shell.execute_reply": "2025-08-31T04:36:48.150092Z",
     "shell.execute_reply.started": "2025-08-31T04:35:16.575862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:31<00:00, 273.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "token_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for review in tqdm(frame['CleanedContext']):\n",
    "    batch_encoder = tokenizer.encode_plus(\n",
    "        text = review,\n",
    "        max_length= 128,\n",
    "        truncation= True,\n",
    "        return_tensors= 'pt',\n",
    "    )\n",
    "    token_ids.append(batch_encoder['input_ids'])\n",
    "    attention_masks.append(batch_encoder['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95781241-490d-48c8-b620-1cf848c0c231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:36:48.152340Z",
     "iopub.status.busy": "2025-08-31T04:36:48.152082Z",
     "iopub.status.idle": "2025-08-31T04:36:49.120839Z",
     "shell.execute_reply": "2025-08-31T04:36:49.120044Z",
     "shell.execute_reply.started": "2025-08-31T04:36:48.152325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "token_ids = [t.squeeze(0) for t in token_ids]\n",
    "attention_masks = [t.squeeze(0) for t in attention_masks]\n",
    "\n",
    "token_ids = pad_sequence(\n",
    "    token_ids, \n",
    "    batch_first= True,\n",
    "    padding_value= tokenizer.pad_token_id\n",
    "    )\n",
    "attention_masks = pad_sequence(\n",
    "    attention_masks,\n",
    "    batch_first= True,\n",
    "    padding_value= tokenizer.pad_token_type_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa50925",
   "metadata": {},
   "source": [
    "# Build Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87e28567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:36:49.122107Z",
     "iopub.status.busy": "2025-08-31T04:36:49.121886Z",
     "iopub.status.idle": "2025-08-31T04:36:49.181331Z",
     "shell.execute_reply": "2025-08-31T04:36:49.180587Z",
     "shell.execute_reply.started": "2025-08-31T04:36:49.122081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    token_ids, \n",
    "    test_size= 0.2, \n",
    "    random_state= 42\n",
    ")\n",
    "train_ids, test_ids = train_test_split(\n",
    "    train_ids, \n",
    "    test_size= 0.125, \n",
    "    random_state= 42\n",
    ")\n",
    "\n",
    "train_masks, val_masks = train_test_split(\n",
    "    attention_masks, \n",
    "    test_size= 0.2, \n",
    "    random_state= 42\n",
    ")\n",
    "train_masks, test_masks = train_test_split(\n",
    "    train_masks, \n",
    "    test_size= 0.125, \n",
    "    random_state= 42\n",
    ")\n",
    "\n",
    "labels = torch.tensor(frame['Label'], dtype= torch.long)\n",
    "train_labels, val_labels = train_test_split(\n",
    "    labels,test_size= 0.2\n",
    "    )\n",
    "train_labels, test_labels = train_test_split(\n",
    "    train_labels,test_size= 0.125\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8857b167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:36:49.183052Z",
     "iopub.status.busy": "2025-08-31T04:36:49.182843Z",
     "iopub.status.idle": "2025-08-31T04:36:49.187355Z",
     "shell.execute_reply": "2025-08-31T04:36:49.186799Z",
     "shell.execute_reply.started": "2025-08-31T04:36:49.183035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_ids, train_masks, train_labels)\n",
    "val_data = TensorDataset(val_ids, val_masks, val_labels)\n",
    "test_data = TensorDataset(test_ids, test_masks, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c4e9a0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:36:49.188688Z",
     "iopub.status.busy": "2025-08-31T04:36:49.188384Z",
     "iopub.status.idle": "2025-08-31T04:36:49.222152Z",
     "shell.execute_reply": "2025-08-31T04:36:49.221550Z",
     "shell.execute_reply.started": "2025-08-31T04:36:49.188667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data, batch_size= 16, \n",
    "    num_workers= 4\n",
    "    )\n",
    "val_loader = DataLoader(\n",
    "    val_data, batch_size= 16, \n",
    "    num_workers= 4\n",
    "    )\n",
    "test_loader = DataLoader(\n",
    "    test_data, batch_size= 16, \n",
    "    num_workers= 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb48878",
   "metadata": {},
   "source": [
    "# BERT for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eb04ad69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:36:49.223691Z",
     "iopub.status.busy": "2025-08-31T04:36:49.222958Z",
     "iopub.status.idle": "2025-08-31T04:36:49.226915Z",
     "shell.execute_reply": "2025-08-31T04:36:49.226331Z",
     "shell.execute_reply.started": "2025-08-31T04:36:49.223673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d04096",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b4faa10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:36:49.228035Z",
     "iopub.status.busy": "2025-08-31T04:36:49.227682Z",
     "iopub.status.idle": "2025-08-31T04:36:49.705658Z",
     "shell.execute_reply": "2025-08-31T04:36:49.704927Z",
     "shell.execute_reply.started": "2025-08-31T04:36:49.228012Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648c72a",
   "metadata": {},
   "source": [
    "## Optim Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5be6c7a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:36:49.706658Z",
     "iopub.status.busy": "2025-08-31T04:36:49.706423Z",
     "iopub.status.idle": "2025-08-31T04:36:49.713710Z",
     "shell.execute_reply": "2025-08-31T04:36:49.713072Z",
     "shell.execute_reply.started": "2025-08-31T04:36:49.706636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "optimizer = AdamW(model.parameters())\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "num_training_steps = EPOCHS * len(train_loader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ac1b8",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a020b-c369-459e-9a23-feafe9659eb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:59:45.165413Z",
     "iopub.status.busy": "2025-08-31T04:59:45.164662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=8,        # giảm nếu OOM\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='/kaggle/working/logs',                 # TensorBoard logs\n",
    "    logging_steps=50,\n",
    "    gradient_accumulation_steps=1,        # tăng nếu muốn mô phỏng batch lớn\n",
    "    fp16=True,                            # mixed precision nếu GPU support\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                          # model BERT đã khai báo\n",
    "    args=training_args,                   # training args\n",
    "    train_dataset=train_data,             # dataset train (Dataset object)\n",
    "    eval_dataset=val_data                 # dataset eval\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92187d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850513a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 557800,
     "sourceId": 1014812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
